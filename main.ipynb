{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30968dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob # lista plików\n",
    "import xml.etree.cElementTree as ET # przechodzenie po XMLu\n",
    "import pandas as pd # data frame, zapisywanie danych do CSV\n",
    "import numpy as np # histogram 2D\n",
    "from tqdm import tqdm # pasek postępu - żeby było wiadomo że coś się dzieje ;)\n",
    " \n",
    "import matplotlib.pyplot as plt # wykresy\n",
    "import matplotlib.cm as cm # palety kolorów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7449d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gpx_file(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Funkcja wczytuje podany plik GPX i zwraca dataframe z jego zawartością\"\"\"\n",
    "    \n",
    "    def find_tag(xml_node: ET.Element, tag: str) -> ET.Element:\n",
    "        \"\"\"Funkcja szuka w XMLu node'a o określonym tagu. Zwraca znaleziony node lub None\"\"\"\n",
    "        found = False\n",
    "        for node in xml_node:\n",
    "            if node.tag.endswith(tag):\n",
    "                found  = True\n",
    "                break\n",
    "        \n",
    "        if found:\n",
    "            return node\n",
    " \n",
    "        return None\n",
    " \n",
    "    # wczytujemy plik XML\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    " \n",
    "    # począwszy od roota szukamy sekcji \"trk\"\n",
    "    trk_node = find_tag(root, \"trk\")\n",
    "    if not trk_node:\n",
    "        return pd.DataFrame()\n",
    " \n",
    "    # mając sekcję \"trk\" szukamy w niej \"trkseg\"\n",
    "    trkseg_node = find_tag(trk_node, \"trkseg\")\n",
    "    if not trkseg_node:\n",
    "        return pd.DataFrame()\n",
    " \n",
    "    # w sekcji \"trkseg\" mamy kolekcję punktów na trasie\n",
    "    points = []\n",
    "    for node in trkseg_node:\n",
    "        # z każdego punktu wyciągamy interesujące nas informacje i dokładamy do listy\n",
    "        elem = node.attrib\n",
    "        for nn in node:\n",
    "            elem[nn.tag.split(\"}\")[-1]] = nn.text\n",
    "        points.append(elem)\n",
    "        \n",
    "    # z listy robimy data frame\n",
    "    points_df = pd.DataFrame(points)\n",
    " \n",
    "    # korekcja typów zebranych danych\n",
    "    points_df['lat'] = points_df['lat'].astype(float)\n",
    "    points_df['lon'] = points_df['lon'].astype(float)\n",
    "    points_df['ele'] = points_df['ele'].astype(float)\n",
    "    points_df['time'] = points_df['time'].apply(lambda s: pd.to_datetime(s))\n",
    "    points_df['filename'] = filename\n",
    " \n",
    "    return points_df[['time', 'filename', 'lon', 'lat', 'ele']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4a67ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish: No matches for wildcard “strava_archive/activities/*.gpx.gz”. See `help expand`.\n",
      "gzip -d strava_archive/activities/*.gpx.gz\n",
      "        ^\n"
     ]
    }
   ],
   "source": [
    "!gzip -d strava_archive/activities/*.gpx.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bec398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_data_gpx = \"strava_archive/activities/*.gpx\"\n",
    "activities_data = \"strava_archive/activities.csv\"\n",
    "activities_data_output = \"strava_archive/activities_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c164d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 161/161 [00:13<00:00, 11.85it/s]\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.DataFrame()\n",
    " \n",
    "# listujemy pliki i każdy z nich parsujemy\n",
    "for gpx_file in tqdm(glob.glob(activities_data_gpx)):\n",
    "    tmp_df = parse_gpx_file(gpx_file)\n",
    " \n",
    "    # wynik parsowania doklejamy do pełnego data frame\n",
    "    full_df = pd.concat([full_df, tmp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d54082",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx_df = full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e48e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('fit2gpx_df.pkl','rb') as f:\n",
    "    fit_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3bf72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([full_df, fit_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8256c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c20016d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_points = full_df[['lon', 'lat', 'filename']].copy()\n",
    "agg_points['lon'] = agg_points['lon'].apply(lambda x: round(x, 4))\n",
    "agg_points['lat'] = agg_points['lat'].apply(lambda x: round(x, 4))\n",
    " \n",
    "agg_points_plot = agg_points.groupby(['lat', 'lon']).nunique().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c534bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.plugins.heat_map.HeatMap at 0x7efda9c60a60>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrum = (np.mean(agg_points_plot['lat']), np.mean(agg_points_plot['lon']))\n",
    " \n",
    "# budujemy obiekt Map będący początkowo tylko podkładem z mapą\n",
    "m = folium.Map(\n",
    "    location =centrum,\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    zoom_start=10,\n",
    "    zoom_control=True\n",
    ")\n",
    " \n",
    "# wyliczamy heatmapę i dodajemy ją do obiektu typu Map\n",
    "HeatMap(agg_points_plot.values.tolist(), radius=10).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "004ca967",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(\"heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca4ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5b6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
